import torch
from torch_geometric.data import Data
# from core.transform_utils.subgraph_extractors import metis_subgraph, random_subgraph
from core.data_utils.pe import add_positional_encoding
from core.data_utils.posenc_stats import compute_posenc_stats
import re

def random_walk(A, n_iter=8):
    Dinv = A.sum(dim=-1).clamp(min=1).pow(-1).unsqueeze(-1)  # D^-1
    RW = A * Dinv
    M = RW
    M_power = M
    # Iterate
    for _ in range(n_iter-1):
        M_power = torch.matmul(M_power, M)
    return M_power


def cal_coarsen_adj(subgraphs_nodes_mask):
    mask = subgraphs_nodes_mask.to(torch.float)
    coarsen_adj = torch.matmul(mask, mask.t())
    return coarsen_adj


def to_sparse(node_mask, edge_mask):
    subgraphs_nodes = node_mask.nonzero().T
    subgraphs_edges = edge_mask.nonzero().T
    return subgraphs_nodes, subgraphs_edges


def combine_subgraphs(edge_index, subgraphs_nodes, subgraphs_edges, num_selected=None, num_nodes=None):
    if num_selected is None:
        num_selected = subgraphs_nodes[0][-1] + 1
    if num_nodes is None:
        num_nodes = subgraphs_nodes[1].max() + 1

    combined_subgraphs = edge_index[:, subgraphs_edges[1]]
    node_label_mapper = edge_index.new_full((num_selected, num_nodes), -1)
    node_label_mapper[subgraphs_nodes[0], subgraphs_nodes[1]
                      ] = torch.arange(len(subgraphs_nodes[1]))
    node_label_mapper = node_label_mapper.reshape(-1)

    inc = torch.arange(num_selected)*num_nodes
    combined_subgraphs += inc[subgraphs_edges[0]]
    combined_subgraphs = node_label_mapper[combined_subgraphs]
    return combined_subgraphs


# class SubgraphsData(Data):
#     def __inc__(self, key, value, *args, **kwargs):
#         num_nodes = self.num_nodes
#         num_edges = self.edge_index.size(-1)
#         if bool(re.search('(combined_subgraphs)', key)):
#             return getattr(self, key[:-len('combined_subgraphs')]+'subgraphs_nodes_mapper').size(0)
#         elif bool(re.search('(subgraphs_batch)', key)):
#             return 1+getattr(self, key)[-1]
#         elif bool(re.search('(nodes_mapper)', key)):
#             return num_nodes
#         elif bool(re.search('(edges_mapper)', key)):
#             return num_edges
#         else:
#             return super().__inc__(key, value, *args, **kwargs)

#     def __cat_dim__(self, key, value, *args, **kwargs):
#         if bool(re.search('(combined_subgraphs)', key)):
#             return -1
#         else:
#             return super().__cat_dim__(key, value, *args, **kwargs)


class PositionalEncodingTransform(object):
    def __init__(self, rw_dim=0, lap_dim=0):
        super().__init__()
        self.rw_dim = rw_dim
        self.lap_dim = lap_dim

    def __call__(self, data):
        data = add_positional_encoding(data, self.rw_dim, self.lap_dim)
        return data

class SuperPixelPositionalEncodingTransform(object):
    def __init__(self, pe_types, cfg):
        super().__init__()
        self.pe_types = pe_types
        self.cfg = cfg

    def __call__(self, data):
        data = compute_posenc_stats(data,
                                    pe_types=self.pe_types,
                                    is_undirected=data.is_undirected(),
                                    cfg=self.cfg)
        return data


class RandomPartitionTransform(object):
    def __init__(self, n_patches, num_hops=1):
        super().__init__()
        self.n_patches = n_patches
        self.num_hops = num_hops

    def __call__(self, data):
        data = SubgraphsData(**{k: v for k, v in data})

        node_masks, edge_masks = random_subgraph(
            data, n_patches=self.n_patches, num_hops=self.num_hops)
        subgraphs_nodes, subgraphs_edges = to_sparse(node_masks, edge_masks)
        combined_subgraphs = combine_subgraphs(
            data.edge_index, subgraphs_nodes, subgraphs_edges, num_selected=self.n_patches, num_nodes=data.num_nodes)

        coarsen_adj = cal_coarsen_adj(node_masks)
        data.coarsen_adj = random_walk(coarsen_adj)

        subgraphs_batch = subgraphs_nodes[0]
        mask = torch.zeros(self.n_patches).bool()
        mask[subgraphs_batch] = True
        data.subgraphs_batch = subgraphs_batch
        data.subgraphs_nodes_mapper = subgraphs_nodes[1]
        data.subgraphs_edges_mapper = subgraphs_edges[1]
        data.combined_subgraphs = combined_subgraphs
        data.mask = mask.unsqueeze(0)

        data.__num_nodes__ = data.num_nodes  # set number of nodes of the current graph
        return data